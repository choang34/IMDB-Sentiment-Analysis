{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Guide Used: https://towardsdatascience.com/a-beginners-guide-to-text-classification-with-scikit-learn-632357e16f3a#f4a3\n#Preparing the Dataset \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-05T19:01:07.931635Z","iopub.execute_input":"2022-11-05T19:01:07.932367Z","iopub.status.idle":"2022-11-05T19:01:07.939239Z","shell.execute_reply.started":"2022-11-05T19:01:07.932327Z","shell.execute_reply":"2022-11-05T19:01:07.938122Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"#Reading the Dataset\ndf_review = pd.read_csv('../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\ndf_review","metadata":{"execution":{"iopub.status.busy":"2022-11-05T19:01:04.531912Z","iopub.execute_input":"2022-11-05T19:01:04.532310Z","iopub.status.idle":"2022-11-05T19:01:05.250587Z","shell.execute_reply.started":"2022-11-05T19:01:04.532280Z","shell.execute_reply":"2022-11-05T19:01:05.249409Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                  review sentiment\n0      One of the other reviewers has mentioned that ...  positive\n1      A wonderful little production. <br /><br />The...  positive\n2      I thought this was a wonderful way to spend ti...  positive\n3      Basically there's a family where a little boy ...  negative\n4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n...                                                  ...       ...\n49995  I thought this movie did a down right good job...  positive\n49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n49997  I am a Catholic taught in parochial elementary...  negative\n49998  I'm going to have to disagree with the previou...  negative\n49999  No one expects the Star Trek movies to be high...  negative\n\n[50000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>I thought this movie did a down right good job...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>I am a Catholic taught in parochial elementary...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>I'm going to have to disagree with the previou...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>No one expects the Star Trek movies to be high...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Creating imbalanced classes\ndf_positive = df_review[df_review['sentiment']=='positive'][:9000]\ndf_negative = df_review[df_review['sentiment']=='negative'][:1000]\n\ndf_review_imb = pd.concat([df_positive, df_negative])","metadata":{"execution":{"iopub.status.busy":"2022-11-05T19:05:36.718421Z","iopub.execute_input":"2022-11-05T19:05:36.718837Z","iopub.status.idle":"2022-11-05T19:05:36.749963Z","shell.execute_reply.started":"2022-11-05T19:05:36.718807Z","shell.execute_reply":"2022-11-05T19:05:36.748990Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                 review sentiment\n0     One of the other reviewers has mentioned that ...  positive\n1     A wonderful little production. <br /><br />The...  positive\n2     I thought this was a wonderful way to spend ti...  positive\n4     Petter Mattei's \"Love in the Time of Money\" is...  positive\n5     Probably my all-time favorite movie, a story o...  positive\n...                                                 ...       ...\n2000  Stranded in Space (1972) MST3K version - a ver...  negative\n2005  I happened to catch this supposed \"horror\" fli...  negative\n2007  waste of 1h45 this nasty little film is one to...  negative\n2010  Warning: This could spoil your movie. Watch it...  negative\n2013  Quite what the producers of this appalling ada...  negative\n\n[10000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Probably my all-time favorite movie, a story o...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2000</th>\n      <td>Stranded in Space (1972) MST3K version - a ver...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2005</th>\n      <td>I happened to catch this supposed \"horror\" fli...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2007</th>\n      <td>waste of 1h45 this nasty little film is one to...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2010</th>\n      <td>Warning: This could spoil your movie. Watch it...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2013</th>\n      <td>Quite what the producers of this appalling ada...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Resampling imbalanced classes\nfrom imblearn.under_sampling import RandomUnderSampler\n\nrus = RandomUnderSampler(random_state = 0)\ndf_review_bal, df_review_bal['sentiment']=rus.fit_resample(df_review_imb[['review']],df_review_imb['sentiment'])\n\ndf_review_bal\n\n#Testing resampling\nprint(df_review_imb.value_counts('sentiment'))\nprint(df_review_bal.value_counts('sentiment'))","metadata":{"execution":{"iopub.status.busy":"2022-11-05T19:13:16.130802Z","iopub.execute_input":"2022-11-05T19:13:16.131195Z","iopub.status.idle":"2022-11-05T19:13:16.171543Z","shell.execute_reply.started":"2022-11-05T19:13:16.131165Z","shell.execute_reply":"2022-11-05T19:13:16.170223Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"sentiment\npositive    9000\nnegative    1000\ndtype: int64\nsentiment\nnegative    1000\npositive    1000\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"#Alternative option of RandomUnderSampler\nlength_negative = len(df_review_imb[df_review_imb['sentiment']=='negative'])\ndf_review_positive = df_review_imb[df_review_imb['sentiment']=='positive'].sample(n=length_negative)\ndf_review_non_positive = df_review_imb[~(df_review_imb['sentiment']=='positive')]\n\ndf_review_bal = pd.concat([\n    df_review_positive, df_review_non_positive\n])\ndf_review_bal.reset_index(drop = True, inplace = True)\ndf_review_bal['sentiment'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-11-05T19:23:03.774752Z","iopub.execute_input":"2022-11-05T19:23:03.775466Z","iopub.status.idle":"2022-11-05T19:23:03.792028Z","shell.execute_reply.started":"2022-11-05T19:23:03.775420Z","shell.execute_reply":"2022-11-05T19:23:03.791186Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"positive    1000\nnegative    1000\nName: sentiment, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"#Splitting data into train and test set\nfrom sklearn.model_selection import train_test_split\ntrain, test = train_test_split(df_review_bal, test_size = 0.2, random_state = 42) \n\ntrain_x, train_y = train['review'], train['sentiment'] #80% of the data will be used to make predictions\ntest_x, test_y = test['review'], test['sentiment'] #20% of the data will be used to test the model\n\n#Test 1: Term Frequency, Inverse Document Frequency (TF-IDF)\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(stop_words='english')\ntrain_x_vector = tfidf.fit_transform(train_x)\ntrain_x_vector\n\n#Visualize TF-IDF\npd.DataFrame.sparse.from_spmatrix(train_x_vector, index=train_x.index, columns=tfidf.get_feature_names())","metadata":{"execution":{"iopub.status.busy":"2022-11-05T19:26:54.337381Z","iopub.execute_input":"2022-11-05T19:26:54.337786Z","iopub.status.idle":"2022-11-05T19:26:55.703728Z","shell.execute_reply.started":"2022-11-05T19:26:54.337755Z","shell.execute_reply":"2022-11-05T19:26:55.702587Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n  warnings.warn(msg, category=FutureWarning)\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"       00  000  00s   01  0126   02   04   07   08   10  ...  zoom  zoomed  \\\n968   0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0     0.0   \n240   0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0     0.0   \n819   0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0     0.0   \n692   0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0     0.0   \n420   0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0     0.0   \n...   ...  ...  ...  ...   ...  ...  ...  ...  ...  ...  ...   ...     ...   \n1130  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0     0.0   \n1294  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0     0.0   \n860   0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0     0.0   \n1459  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0     0.0   \n1126  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0     0.0   \n\n      zooming  zooms  zorro  zzzzzzzzzzzzzzzzzz  æon  élan  être  über  \n968       0.0    0.0    0.0            0.000000  0.0   0.0   0.0   0.0  \n240       0.0    0.0    0.0            0.000000  0.0   0.0   0.0   0.0  \n819       0.0    0.0    0.0            0.000000  0.0   0.0   0.0   0.0  \n692       0.0    0.0    0.0            0.000000  0.0   0.0   0.0   0.0  \n420       0.0    0.0    0.0            0.000000  0.0   0.0   0.0   0.0  \n...       ...    ...    ...                 ...  ...   ...   ...   ...  \n1130      0.0    0.0    0.0            0.000000  0.0   0.0   0.0   0.0  \n1294      0.0    0.0    0.0            0.000000  0.0   0.0   0.0   0.0  \n860       0.0    0.0    0.0            0.000000  0.0   0.0   0.0   0.0  \n1459      0.0    0.0    0.0            0.185653  0.0   0.0   0.0   0.0  \n1126      0.0    0.0    0.0            0.000000  0.0   0.0   0.0   0.0  \n\n[1600 rows x 22172 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>00</th>\n      <th>000</th>\n      <th>00s</th>\n      <th>01</th>\n      <th>0126</th>\n      <th>02</th>\n      <th>04</th>\n      <th>07</th>\n      <th>08</th>\n      <th>10</th>\n      <th>...</th>\n      <th>zoom</th>\n      <th>zoomed</th>\n      <th>zooming</th>\n      <th>zooms</th>\n      <th>zorro</th>\n      <th>zzzzzzzzzzzzzzzzzz</th>\n      <th>æon</th>\n      <th>élan</th>\n      <th>être</th>\n      <th>über</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>968</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>240</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>819</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>692</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>420</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1130</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1294</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.185653</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1126</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1600 rows × 22172 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Testing the Accuracy\ntest_x_vector = tfidf.transform(test_x)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T19:27:02.477905Z","iopub.execute_input":"2022-11-05T19:27:02.478390Z","iopub.status.idle":"2022-11-05T19:27:02.553464Z","shell.execute_reply.started":"2022-11-05T19:27:02.478347Z","shell.execute_reply":"2022-11-05T19:27:02.552361Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"#Support Vector Machines (SVM)\nfrom sklearn.svm import SVC\nsvc = SVC(kernel= 'linear')\nsvc.fit(train_x_vector, train_y)\n\nprint(svc.predict(tfidf.transform(['A good movie'])))\nprint(svc.predict(tfidf.transform(['An excellent movie'])))\nprint(svc.predict(tfidf.transform(['I did not like this movie at all'])))","metadata":{"execution":{"iopub.status.busy":"2022-11-05T19:33:18.684871Z","iopub.execute_input":"2022-11-05T19:33:18.685260Z","iopub.status.idle":"2022-11-05T19:33:20.900036Z","shell.execute_reply.started":"2022-11-05T19:33:18.685226Z","shell.execute_reply":"2022-11-05T19:33:20.899094Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"['positive']\n['positive']\n['negative']\n","output_type":"stream"}]},{"cell_type":"code","source":"#Evaluating other classifers \n\n#Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\ndec_tree = DecisionTreeClassifier()\ndec_tree.fit(train_x_vector, train_y)\n\n#Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(train_x_vector.toarray(), train_y)\n\n#Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlog_reg = LogisticRegression()\nlog_reg.fit(train_x_vector, train_y)\n\n#Mean Accuracy\n# svc.score('Test samples', 'True labels')\nprint(svc.score(test_x_vector, test_y))\nprint(dec_tree.score(test_x_vector, test_y))\nprint(gnb.score(test_x_vector.toarray(), test_y))\nprint(log_reg.score(test_x_vector, test_y))","metadata":{"execution":{"iopub.status.busy":"2022-11-05T19:36:43.912944Z","iopub.execute_input":"2022-11-05T19:36:43.913323Z","iopub.status.idle":"2022-11-05T19:36:46.316858Z","shell.execute_reply.started":"2022-11-05T19:36:43.913294Z","shell.execute_reply":"2022-11-05T19:36:46.315597Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"0.8375\n0.65\n0.6625\n0.83\n","output_type":"stream"}]},{"cell_type":"markdown","source":"SVM and Logistic Regression are the most accurate means of classifying sentiment for the model, SVM will be used in favor because of its higher value","metadata":{}},{"cell_type":"code","source":"#Obtaining the F1 Score\n#F1 score reaches its best value at 1 and worst score at 0.\nfrom sklearn.metrics import f1_score\nf1_score(test_y, svc.predict(test_x_vector), labels=['positive', 'negative'], average=None)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T19:38:12.646076Z","iopub.execute_input":"2022-11-05T19:38:12.646976Z","iopub.status.idle":"2022-11-05T19:38:13.122246Z","shell.execute_reply.started":"2022-11-05T19:38:12.646938Z","shell.execute_reply":"2022-11-05T19:38:13.121135Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"array([0.84029484, 0.8346056 ])"},"metadata":{}}]},{"cell_type":"markdown","source":"84 Positives, 83 Negative labels","metadata":{}},{"cell_type":"code","source":"#Classification Report\nfrom sklearn.metrics import classification_report\nprint(classification_report(test_y, svc.predict(test_x_vector), labels=['positive', 'negative']))","metadata":{"execution":{"iopub.status.busy":"2022-11-05T19:38:48.002100Z","iopub.execute_input":"2022-11-05T19:38:48.002505Z","iopub.status.idle":"2022-11-05T19:38:48.484553Z","shell.execute_reply.started":"2022-11-05T19:38:48.002441Z","shell.execute_reply":"2022-11-05T19:38:48.483475Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n    positive       0.82      0.86      0.84       199\n    negative       0.85      0.82      0.83       201\n\n    accuracy                           0.84       400\n   macro avg       0.84      0.84      0.84       400\nweighted avg       0.84      0.84      0.84       400\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\nconf_mat = confusion_matrix(test_y, svc.predict(test_x_vector), labels=['positive', 'negative'])\nprint(conf_mat)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T19:40:07.231378Z","iopub.execute_input":"2022-11-05T19:40:07.232581Z","iopub.status.idle":"2022-11-05T19:40:07.698259Z","shell.execute_reply.started":"2022-11-05T19:40:07.232540Z","shell.execute_reply":"2022-11-05T19:40:07.697179Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"[[171  28]\n [ 37 164]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"171 Positive and 164 Negatives","metadata":{}},{"cell_type":"code","source":"#GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n#set the parameters\nparameters = {'C': [1,4,8,16,32] ,'kernel':['linear', 'rbf']}\nsvc = SVC()\nsvc_grid = GridSearchCV(svc,parameters, cv=5)\n\nsvc_grid.fit(train_x_vector, train_y)\nprint(svc_grid.best_params_)\nprint(svc_grid.best_estimator_)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T19:42:04.939069Z","iopub.execute_input":"2022-11-05T19:42:04.939432Z","iopub.status.idle":"2022-11-05T19:43:38.326558Z","shell.execute_reply.started":"2022-11-05T19:42:04.939405Z","shell.execute_reply":"2022-11-05T19:43:38.325522Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"{'C': 4, 'kernel': 'rbf'}\nSVC(C=4)\n","output_type":"stream"}]}]}